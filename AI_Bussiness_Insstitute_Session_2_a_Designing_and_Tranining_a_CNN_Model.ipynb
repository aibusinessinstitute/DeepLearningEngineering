{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI Bussiness Insstitute Session 2.a - Designing and Tranining a CNN Model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading Dataset"
      ],
      "metadata": {
        "id": "l8o8bBAhSIZn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJNr-kgmRzJO"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --no-cache-dir gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1mLkyvMB7EBbMpAA4f_uLBxOr34U84miD\n",
        "!unzip -q retail_4_classes.zip"
      ],
      "metadata": {
        "id": "aX2ziDEsSMiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "hvoCVRc_SVkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "A1FCsN0ZSQyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Preparation\n",
        "\n",
        "Note: you can also create your own dataset wrapper like in the previous lecture\n",
        "\n",
        "https://colab.research.google.com/drive/1-uxaA8ZhpgLtctCKrzm2tF_U-_aeF_ci#scrollTo=nZld2EsoQkn9"
      ],
      "metadata": {
        "id": "ka_Zi2WWSfV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "preprocessing = transforms.Compose([\n",
        "   transforms.Resize([224,224]),   \n",
        "   transforms.RandomRotation(5),                             \n",
        "   transforms.ToTensor(), \n",
        "])\n",
        "\n",
        "trainset = ImageFolder('retail_4_classes/train', transform = preprocessing)\n",
        "dataloader = DataLoader(dataset=trainset, batch_size=16, \n",
        "                        shuffle=True)"
      ],
      "metadata": {
        "id": "t8fOc_waSeGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test reading the dataset"
      ],
      "metadata": {
        "id": "RJ2O0wgYTUrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = trainset[100]\n",
        "\n",
        "print(img.shape)\n",
        "print(label)\n",
        "image = np.transpose(img, [1,2,0])\n",
        "\n",
        "plt.imshow(image)"
      ],
      "metadata": {
        "id": "A7dqzpwgTT56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the dataset loader"
      ],
      "metadata": {
        "id": "zc9F2bjMTt13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (x,y) in enumerate(dataloader):\n",
        "    print(x.shape, y.shape)\n",
        "    break"
      ],
      "metadata": {
        "id": "sdolLIANTbX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 5\n",
        "image = np.transpose(x[idx].cpu().numpy(), [1,2,0])\n",
        "print(y[idx])\n",
        "plt.imshow(image)"
      ],
      "metadata": {
        "id": "BLiC24H_Tx7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Your own Model"
      ],
      "metadata": {
        "id": "DLCWUX18T95_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, n_class):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=7, stride=1, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool3 =  nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.classifier =  nn.Conv2d(64, n_class, kernel_size=1, stride=1, padding=0)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        relu = self.relu\n",
        "\n",
        "        conv1 = relu(self.conv1(x))\n",
        "        pool1 = self.pool1(conv1)\n",
        "\n",
        "        conv2 = relu(self.conv2(pool1))+pool1\n",
        "        pool2 = self.pool2(conv2)\n",
        "\n",
        "        conv3 = relu(self.conv3(pool2))\n",
        "        pool3 = self.pool3(conv3)\n",
        "\n",
        "      \n",
        "        global_pool = pool3.mean([2, 3], keepdim=True) # calc mean in row and cols\n",
        "      \n",
        "        out = self.classifier(global_pool)\n",
        "        out = torch.squeeze(out)\n",
        "\n",
        "        # in case the batch contains only single frame\n",
        "        if len(out.shape)<2:\n",
        "            out = torch.unsqueeze(out, 0)\n",
        "            \n",
        "        return out\n",
        "\n"
      ],
      "metadata": {
        "id": "LDgMeYUWT0he"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the model"
      ],
      "metadata": {
        "id": "JqHgPYiyUll2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net(4)\n",
        "pred = model(x)\n",
        "\n",
        "print(pred.shape)\n",
        "print(len(pred.shape))"
      ],
      "metadata": {
        "id": "RzlKT5QhUlCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Utilities"
      ],
      "metadata": {
        "id": "lPmc4O6tVv0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.functional import cross_entropy\n",
        "\n",
        "def training(model, data_loader, objective_function, device, optimizer, max_iter=-1):\n",
        "    model.train()\n",
        "\n",
        "    for i, (x,y) in enumerate(data_loader):\n",
        "        # moves the trainig data to device (possibly GPU)\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # inference\n",
        "        logits = model(x)\n",
        "\n",
        "        # calculate the error score\n",
        "        loss = objective_function(logits, y) # menggunakan cross_entropy\n",
        "\n",
        "        # updating the parameters\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i==max_iter:\n",
        "            break"
      ],
      "metadata": {
        "id": "jYJc6cnwUGb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cpu = torch.device('cpu')\n",
        "def count_acc(logits, label, device = cpu):\n",
        "    pred = torch.argmax(logits, dim=1)\n",
        "    return (pred == label).to(device).type(torch.FloatTensor).mean().item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluation(model, data_loader, objective_function, device, max_iter=-1):\n",
        "    model.eval()\n",
        "\n",
        "    loss_values = []\n",
        "    accuracy_values = []\n",
        "\n",
        "    for i, (x,y) in enumerate(data_loader):\n",
        "        # moves the trainig data to device (possibly GPU)\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # inference\n",
        "        logits = model(x)\n",
        "\n",
        "        # calculate the error score\n",
        "        loss = objective_function(logits, y)\n",
        "        acc = count_acc(logits, y, device)\n",
        "\n",
        "        loss_values.append(loss.item())\n",
        "        accuracy_values.append(acc)\n",
        "\n",
        "        if i==max_iter:\n",
        "            break\n",
        "\n",
        "    # calculate the average value of loss and accuracy\n",
        "    loss = np.mean(loss_values)\n",
        "    accuracy = np.mean(accuracy_values)\n",
        "\n",
        "    return loss, accuracy"
      ],
      "metadata": {
        "id": "QRLM3qqXVzEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "L_4LW9TxWSrA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the model"
      ],
      "metadata": {
        "id": "wTmfGM9rWVt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net(4)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
      ],
      "metadata": {
        "id": "9W0UA00NWQgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "jK1x1VIAW3xm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "'''training data'''\n",
        "trainset = ImageFolder('retail_4_classes/train', transform = preprocessing)\n",
        "train_loader = DataLoader(dataset=trainset, batch_size=batch_size, \n",
        "                        shuffle=True)\n",
        "\n",
        "'''validation data'''\n",
        "val_preprocessing = transforms.Compose([\n",
        "   transforms.Resize([224,224]),                            \n",
        "   transforms.ToTensor(), \n",
        "])\n",
        "valset = ImageFolder('retail_4_classes/val', transform = val_preprocessing)\n",
        "val_loader = DataLoader(dataset=valset, batch_size=batch_size, \n",
        "                        shuffle=False)"
      ],
      "metadata": {
        "id": "O7wsIOVeW6X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Process"
      ],
      "metadata": {
        "id": "pkbhWEldWXqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "model_checkpoint = 'best_model.pth'\n",
        "\n",
        "best_acc = 0\n",
        "for e in range(epochs):\n",
        "    training(model, train_loader, cross_entropy, device, optimizer)\n",
        "    loss, acc = evaluation(model, val_loader, cross_entropy, device)\n",
        "    scheduler.step()\n",
        "\n",
        "    print('epoch %d loss=%f acc=%f'%(e, loss, acc))\n",
        "    \n",
        "    if acc>best_acc:\n",
        "        torch.save(model.state_dict(), model_checkpoint)\n",
        "        best_acc = acc"
      ],
      "metadata": {
        "id": "KaniQqYvWYxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the trained model and testing it"
      ],
      "metadata": {
        "id": "o0GtdKxaXspF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net(4)\n",
        "\n",
        "model.load_state_dict(torch.load(model_checkpoint))\n",
        "model.to(device)\n",
        "\n",
        "'''validation data'''\n",
        "valset = ImageFolder('retail_4_classes/val', transform = val_preprocessing)\n",
        "val_loader = DataLoader(dataset=valset, batch_size=1, \n",
        "                        shuffle=False)\n",
        "\n",
        "loss, acc = evaluation(model, val_loader, cross_entropy, device, max_iter=-1)\n",
        "print('val:', loss, acc)"
      ],
      "metadata": {
        "id": "d9xzKxcXXPgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference function"
      ],
      "metadata": {
        "id": "jystP560aRHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def predict(model, x, device=cpu):\n",
        "    model.eval()\n",
        "\n",
        "    logits = model(x.to(device))\n",
        "    pred = torch.argmax(logits, dim=1)\n",
        "    return pred"
      ],
      "metadata": {
        "id": "PutR92FqYVSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (x,y) in enumerate(dataloader):\n",
        "    print(x.shape, y.shape)\n",
        "    break\n",
        "\n",
        "prediction = predict(model, x, device)\n",
        "\n",
        "print('preds:', prediction)\n",
        "print('label:', y)"
      ],
      "metadata": {
        "id": "KPx-MlKxYXug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "S4nI1POSYkXy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}