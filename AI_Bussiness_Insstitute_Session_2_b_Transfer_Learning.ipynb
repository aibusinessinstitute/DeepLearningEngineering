{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI Bussiness Insstitute Session 2.b - Transfer Learning.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading Dataset"
      ],
      "metadata": {
        "id": "l8o8bBAhSIZn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJNr-kgmRzJO"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --no-cache-dir gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1mLkyvMB7EBbMpAA4f_uLBxOr34U84miD\n",
        "!unzip -q retail_4_classes.zip"
      ],
      "metadata": {
        "id": "aX2ziDEsSMiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "hvoCVRc_SVkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "A1FCsN0ZSQyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Preparation\n",
        "\n",
        "Note: you can also create your own dataset wrapper like in the previous lecture\n",
        "\n",
        "https://colab.research.google.com/drive/1-uxaA8ZhpgLtctCKrzm2tF_U-_aeF_ci#scrollTo=nZld2EsoQkn9"
      ],
      "metadata": {
        "id": "ka_Zi2WWSfV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "preprocessing = transforms.Compose([\n",
        "   transforms.Resize([224,224]),   \n",
        "   transforms.RandomRotation(5),                             \n",
        "   transforms.ToTensor(), \n",
        "])\n",
        "\n",
        "trainset = ImageFolder('retail_4_classes/train', transform = preprocessing)\n",
        "dataloader = DataLoader(dataset=trainset, batch_size=16, \n",
        "                        shuffle=True)"
      ],
      "metadata": {
        "id": "t8fOc_waSeGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test reading the dataset"
      ],
      "metadata": {
        "id": "RJ2O0wgYTUrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = trainset[100]\n",
        "\n",
        "print(img.shape)\n",
        "print(label)\n",
        "image = np.transpose(img, [1,2,0])\n",
        "\n",
        "plt.imshow(image)"
      ],
      "metadata": {
        "id": "A7dqzpwgTT56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the dataset loader"
      ],
      "metadata": {
        "id": "zc9F2bjMTt13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (x,y) in enumerate(dataloader):\n",
        "    print(x.shape, y.shape)\n",
        "    break"
      ],
      "metadata": {
        "id": "sdolLIANTbX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 5\n",
        "image = np.transpose(x[idx].cpu().numpy(), [1,2,0])\n",
        "print(y[idx])\n",
        "plt.imshow(image)"
      ],
      "metadata": {
        "id": "BLiC24H_Tx7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Model from Pre-trained Architecture"
      ],
      "metadata": {
        "id": "NUiUGjThbCyP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install timm\n",
        "https://github.com/rwightman/pytorch-image-models"
      ],
      "metadata": {
        "id": "3zENyPO4bOQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "id": "7szeiu7abMnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the model\n",
        "\n",
        "Check https://github.com/rwightman/pytorch-image-models#models for details of the models"
      ],
      "metadata": {
        "id": "gUUlnz2ebUDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import timm\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, n_class, pretrained=True):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.backbone = timm.create_model(model_name='efficientnet_b0', num_classes=n_class, pretrained=pretrained)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.backbone(x)\n",
        "            \n",
        "        return out\n"
      ],
      "metadata": {
        "id": "htat8IcWa9Se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the model"
      ],
      "metadata": {
        "id": "JqHgPYiyUll2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net(4)\n",
        "pred = model(x)\n",
        "\n",
        "print(pred.shape)\n",
        "print(len(pred.shape))"
      ],
      "metadata": {
        "id": "RzlKT5QhUlCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Utilities"
      ],
      "metadata": {
        "id": "lPmc4O6tVv0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.functional import cross_entropy\n",
        "\n",
        "def training(model, data_loader, objective_function, device, optimizer, max_iter=-1):\n",
        "    model.train()\n",
        "\n",
        "    for i, (x,y) in enumerate(data_loader):\n",
        "        # moves the trainig data to device (possibly GPU)\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # inference\n",
        "        logits = model(x)\n",
        "\n",
        "        # calculate the error score\n",
        "        loss = objective_function(logits, y) # menggunakan cross_entropy\n",
        "\n",
        "        # updating the parameters\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i==max_iter:\n",
        "            break"
      ],
      "metadata": {
        "id": "jYJc6cnwUGb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cpu = torch.device('cpu')\n",
        "def count_acc(logits, label, device = cpu):\n",
        "    pred = torch.argmax(logits, dim=1)\n",
        "    return (pred == label).to(device).type(torch.FloatTensor).mean().item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluation(model, data_loader, objective_function, device, max_iter=-1):\n",
        "    model.eval()\n",
        "\n",
        "    loss_values = []\n",
        "    accuracy_values = []\n",
        "\n",
        "    for i, (x,y) in enumerate(data_loader):\n",
        "        # moves the trainig data to device (possibly GPU)\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # inference\n",
        "        logits = model(x)\n",
        "\n",
        "        # calculate the error score\n",
        "        loss = objective_function(logits, y)\n",
        "        acc = count_acc(logits, y, device)\n",
        "\n",
        "        loss_values.append(loss.item())\n",
        "        accuracy_values.append(acc)\n",
        "\n",
        "        if i==max_iter:\n",
        "            break\n",
        "\n",
        "    # calculate the average value of loss and accuracy\n",
        "    loss = np.mean(loss_values)\n",
        "    accuracy = np.mean(accuracy_values)\n",
        "\n",
        "    return loss, accuracy"
      ],
      "metadata": {
        "id": "QRLM3qqXVzEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "L_4LW9TxWSrA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "jK1x1VIAW3xm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "'''training data'''\n",
        "trainset = ImageFolder('retail_4_classes/train', transform = preprocessing)\n",
        "train_loader = DataLoader(dataset=trainset, batch_size=batch_size, \n",
        "                        shuffle=True)\n",
        "\n",
        "'''validation data'''\n",
        "val_preprocessing = transforms.Compose([\n",
        "   transforms.Resize([224,224]),                            \n",
        "   transforms.ToTensor(), \n",
        "])\n",
        "valset = ImageFolder('retail_4_classes/val', transform = val_preprocessing)\n",
        "val_loader = DataLoader(dataset=valset, batch_size=batch_size, \n",
        "                        shuffle=False)"
      ],
      "metadata": {
        "id": "O7wsIOVeW6X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the model (training from scratch)"
      ],
      "metadata": {
        "id": "wTmfGM9rWVt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net(4, pretrained=False)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
      ],
      "metadata": {
        "id": "9W0UA00NWQgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Process"
      ],
      "metadata": {
        "id": "pkbhWEldWXqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "model_checkpoint = 'best_model.pth'\n",
        "\n",
        "best_acc = 0\n",
        "for e in range(epochs):\n",
        "    training(model, train_loader, cross_entropy, device, optimizer)\n",
        "    loss, acc = evaluation(model, val_loader, cross_entropy, device)\n",
        "    scheduler.step()\n",
        "\n",
        "    print('epoch %d loss=%f acc=%f'%(e, loss, acc))\n",
        "    \n",
        "    if acc>best_acc:\n",
        "        torch.save(model.state_dict(), model_checkpoint)\n",
        "        best_acc = acc"
      ],
      "metadata": {
        "id": "KaniQqYvWYxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the model (fine tuning)"
      ],
      "metadata": {
        "id": "wm562m4Gep5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net(4, pretrained=True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
      ],
      "metadata": {
        "id": "kqCghnitep5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Process"
      ],
      "metadata": {
        "id": "0A4Q24nIep5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "model_checkpoint = 'best_model.pth'\n",
        "\n",
        "best_acc = 0\n",
        "for e in range(epochs):\n",
        "    training(model, train_loader, cross_entropy, device, optimizer)\n",
        "    loss, acc = evaluation(model, val_loader, cross_entropy, device)\n",
        "    scheduler.step()\n",
        "\n",
        "    print('epoch %d loss=%f acc=%f'%(e, loss, acc))\n",
        "    \n",
        "    if acc>best_acc:\n",
        "        torch.save(model.state_dict(), model_checkpoint)\n",
        "        best_acc = acc"
      ],
      "metadata": {
        "id": "yNNwjyPKep5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the trained model and testing it"
      ],
      "metadata": {
        "id": "o0GtdKxaXspF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net(4)\n",
        "\n",
        "model.load_state_dict(torch.load(model_checkpoint))\n",
        "model.to(device)\n",
        "\n",
        "'''validation data'''\n",
        "valset = ImageFolder('retail_4_classes/val', transform = val_preprocessing)\n",
        "val_loader = DataLoader(dataset=valset, batch_size=1, \n",
        "                        shuffle=False)\n",
        "\n",
        "loss, acc = evaluation(model, val_loader, cross_entropy, device, max_iter=-1)\n",
        "print('val:', loss, acc)"
      ],
      "metadata": {
        "id": "d9xzKxcXXPgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference function"
      ],
      "metadata": {
        "id": "jystP560aRHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def predict(model, x, device=cpu):\n",
        "    model.eval()\n",
        "\n",
        "    logits = model(x.to(device))\n",
        "    pred = torch.argmax(logits, dim=1)\n",
        "    return pred"
      ],
      "metadata": {
        "id": "PutR92FqYVSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (x,y) in enumerate(dataloader):\n",
        "    print(x.shape, y.shape)\n",
        "    break\n",
        "\n",
        "prediction = predict(model, x, device)\n",
        "\n",
        "print('preds:', prediction)\n",
        "print('label:', y)"
      ],
      "metadata": {
        "id": "KPx-MlKxYXug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning Model"
      ],
      "metadata": {
        "id": "CSKhxwoXfFF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import timm\n",
        "\n",
        "class NetTransferLearning(nn.Module):\n",
        "    def __init__(self, n_class, pretrained=True, model_name='efficientnet_b0', feat_size=1280):\n",
        "        super(NetTransferLearning, self).__init__()\n",
        "\n",
        "        self.backbone = timm.create_model(model_name=model_name, num_classes=n_class, pretrained=pretrained)\n",
        "        self.backbone._modules['classifier'] = nn.Identity()\n",
        "\n",
        "        self.predictor = nn.Linear(in_features=feat_size, out_features=n_class, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        feat = self.backbone(x)\n",
        "        out = self.predictor(feat)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "R9i4hjfhfEMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the model (transfer learning)"
      ],
      "metadata": {
        "id": "AymDR9sigl5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NetTransferLearning(4, pretrained=True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.predictor.parameters(), lr=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
      ],
      "metadata": {
        "id": "-GYal26Dgl5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.backbone._modules['conv_stem'].weight[0,0])\n",
        "print(model.predictor.weight)"
      ],
      "metadata": {
        "id": "-aRvZsfBhoMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Process"
      ],
      "metadata": {
        "id": "OsRz-RZkgl5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "model_checkpoint = 'best_model.pth'\n",
        "\n",
        "best_acc = 0\n",
        "for e in range(epochs):\n",
        "    training(model, train_loader, cross_entropy, device, optimizer)\n",
        "    loss, acc = evaluation(model, val_loader, cross_entropy, device)\n",
        "    scheduler.step()\n",
        "\n",
        "    print('epoch %d loss=%f acc=%f'%(e, loss, acc))\n",
        "    \n",
        "    if acc>best_acc:\n",
        "        torch.save(model.state_dict(), model_checkpoint)\n",
        "        best_acc = acc"
      ],
      "metadata": {
        "id": "huQux-Yegl5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the trained model and testing it"
      ],
      "metadata": {
        "id": "I28NGe34gl5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(model_checkpoint))\n",
        "model.to(device)\n",
        "\n",
        "'''validation data'''\n",
        "valset = ImageFolder('retail_4_classes/val', transform = val_preprocessing)\n",
        "val_loader = DataLoader(dataset=valset, batch_size=1, \n",
        "                        shuffle=False)\n",
        "\n",
        "loss, acc = evaluation(model, val_loader, cross_entropy, device, max_iter=-1)\n",
        "print('val:', loss, acc)"
      ],
      "metadata": {
        "id": "F4uK_nvngl5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.backbone._modules['conv_stem'].weight[0,0])\n",
        "print(model.predictor.weight)"
      ],
      "metadata": {
        "id": "dkNDqeelg_Rb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}