{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI Bussiness Insstitute Session 1.c - traffic_sign.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading Datset"
      ],
      "metadata": {
        "id": "JYAV0vTo5RYn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Update the gdown first so that it can download large-sized file"
      ],
      "metadata": {
        "id": "O5HjS7ZX5VBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-cache-dir gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0qu6c7R_OgR",
        "outputId": "24d6f9f0-c7a1-4d81-9a65-3b75334a1159"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.63.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading the dataset"
      ],
      "metadata": {
        "id": "T9hQWz0E5ZAX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jcb4MA9B9XVi",
        "outputId": "e84e1082-07a6-4f28-ddca-ce1e2f9868c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1nlC561JoAyFjMg9cuGyGf_9h77yRgydW\n",
            "To: /content/traffic_sign.zip\n",
            "100% 40.1M/40.1M [00:00<00:00, 69.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown https://drive.google.com/uc?id=1nlC561JoAyFjMg9cuGyGf_9h77yRgydW"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q -o traffic_sign.zip"
      ],
      "metadata": {
        "id": "XRJGIpau9uFb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "zx2rG-Tb5bTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from skimage.feature import hog"
      ],
      "metadata": {
        "id": "NImHRNYv_aYs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "np.random.seed(1337)"
      ],
      "metadata": {
        "id": "ccih91xfg466"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Loader"
      ],
      "metadata": {
        "id": "lwc8CVuo5fMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TrafficSignImageDataset(Dataset):\n",
        "\n",
        "    def __init__(self, path, transform=None):\n",
        "        \n",
        "        folders = os.listdir(path)\n",
        "        folders = [x for x in folders if os.path.isdir(os.path.join(path, x))]\n",
        "        \n",
        "        self.transform=transform\n",
        "\n",
        "        self.filenames = []\n",
        "        self.labels = []\n",
        "    \n",
        "        for label, folder in enumerate(folders):\n",
        "            folderpath = os.path.join(path, folder)\n",
        "            \n",
        "            files = os.listdir(folderpath)\n",
        "            np.random.shuffle(files)\n",
        "    \n",
        "            for f in files:\n",
        "                filename = os.path.join(folderpath, f)\n",
        "                self.filenames.append(filename)\n",
        "                self.labels.append(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        filename, label = self.filenames[i], self.labels[i]\n",
        "        image = Image.open(filename).convert('RGB')\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "nZld2EsoQkn9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "batch_size = 16\n",
        "root = 'traffic_sign'\n",
        "\n",
        "preprocessing = transforms.Compose([               \n",
        "    transforms.Resize([40,40]),  \n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomCrop([32, 32]),   \n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor(),       \n",
        "])\n",
        "\n",
        "dataset = TrafficSignImageDataset(root, transform=preprocessing)\n",
        "data_loader = DataLoader(dataset=dataset,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True, num_workers=2)\n"
      ],
      "metadata": {
        "id": "MqX61otgUeiq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (x,y) in enumerate(data_loader):\n",
        "    print(x.shape, y.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WY-AFSEU5hQ",
        "outputId": "19e14485-573d-46ba-9db2-5756b75ed788"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 1, 32, 32]) torch.Size([16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x[0][0].numpy(), cmap='gray', vmin=0, vmax=1.)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "w7IW7cb58qsD",
        "outputId": "bd48cd3c-35ae-47e8-abb1-bb0f35c8cf6f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7a8afa3190>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "eBo4QIOEVoEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, feat_size, n_class):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = torch.nn.Linear(feat_size, 128)\n",
        "        self.layer2 = torch.nn.Linear(128, 64)\n",
        "        self.layer3 = torch.nn.Linear(64, 16)\n",
        "    \n",
        "        self.classifier =  torch.nn.Linear(16, n_class)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        relu = self.relu\n",
        "        x = x.reshape(-1,32*32)\n",
        "        x = relu(self.layer1(x))\n",
        "        x = relu(self.layer2(x))\n",
        "        x = relu(self.layer3(x))\n",
        "\n",
        "        out = relu(self.classifier(x))\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "qwYQAI_uVpzk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor = Net(32*32, 10)\n",
        "pred = predictor(x)"
      ],
      "metadata": {
        "id": "9QboNyUiXFOV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.argmax(pred, dim=1))\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxmJmhn0XZLd",
        "outputId": "1c0cd042-b3e8-43e3-8ce2-53a8ae03efff"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4, 8, 8, 4, 4, 4, 8, 4, 8, 8, 4, 8, 8, 4, 4, 8])\n",
            "tensor([4, 3, 5, 0, 0, 4, 1, 0, 4, 3, 2, 9, 6, 2, 1, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "OVmoe9XRVKb0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.functional import cross_entropy\n",
        "\n",
        "def training(model, optimizer, data_loader, objective_function, device, max_iter=-1):\n",
        "    model.train()\n",
        "\n",
        "    for i, (x,y) in enumerate(data_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        logits = model(x)\n",
        "        \n",
        "        loss = objective_function(logits, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i==max_iter:\n",
        "            break\n",
        "    \n",
        "    model.eval()"
      ],
      "metadata": {
        "id": "riStXFbCU_1l"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cpu = torch.device('cpu')\n",
        "def count_acc(logits, label, device = cpu):\n",
        "    pred = torch.argmax(logits, dim=1)\n",
        "    return (pred == label).to(device).type(torch.FloatTensor).mean().item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluation(model, data_loader, objective_function, device, max_iter=-1):\n",
        "    model.eval()\n",
        "\n",
        "    loss_values = []\n",
        "    accuracy_values = []\n",
        "\n",
        "    for i, (x,y) in enumerate(data_loader):\n",
        "        \n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            \n",
        "            logits = model(x)\n",
        "\n",
        "            loss = objective_function(logits, y)\n",
        "            acc = count_acc(logits, y, device)\n",
        "\n",
        "        loss_values.append(loss.item())\n",
        "        accuracy_values.append(acc)\n",
        "\n",
        "        if i==max_iter:\n",
        "            break\n",
        "\n",
        "    loss = np.mean(loss_values)\n",
        "    accuracy = np.mean(accuracy_values)\n",
        "\n",
        "    return loss, accuracy"
      ],
      "metadata": {
        "id": "B_AkqTH-VZ9x"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor = Net(32*32, 10)\n",
        "pred = predictor(x)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "predictor.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(predictor.parameters(), lr=3e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.5)"
      ],
      "metadata": {
        "id": "3zHIgVvqYfn3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "model_checkpoint = 'best_model.pth'\n",
        "\n",
        "best_acc = 0\n",
        "for e in range(epochs):\n",
        "    training(predictor, optimizer, data_loader, cross_entropy, device, max_iter=-1)\n",
        "    \n",
        "    loss, acc = evaluation(predictor, data_loader, cross_entropy, device, max_iter=-1)\n",
        "    scheduler.step()\n",
        "\n",
        "    print('epoch %d loss=%f acc=%f'%(e, loss, acc))\n",
        "    \n",
        "    if acc>=best_acc:\n",
        "        predictor.eval()\n",
        "        torch.save(predictor.state_dict(), model_checkpoint)\n",
        "        best_acc = acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_b3JNrxYDRj",
        "outputId": "ecae5692-86b5-4c1c-ccec-5fcd4f1925b2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 loss=2.134897 acc=0.244907\n",
            "epoch 1 loss=1.886597 acc=0.366667\n",
            "epoch 2 loss=1.768032 acc=0.456481\n",
            "epoch 3 loss=1.673920 acc=0.519444\n",
            "epoch 4 loss=1.651532 acc=0.496296\n",
            "epoch 5 loss=1.581129 acc=0.544907\n",
            "epoch 6 loss=1.539218 acc=0.540278\n",
            "epoch 7 loss=1.480579 acc=0.577778\n",
            "epoch 8 loss=1.428315 acc=0.586111\n",
            "epoch 9 loss=1.416262 acc=0.594907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zDkkkIKj9vLR"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}